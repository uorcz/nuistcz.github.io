---
layout:     post
title:      Python爬虫实战
subtitle:   用selenium爬取JS动态页面
date:       2018-07-05
author:     Masa
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Python
    - Spider
---

## 前言

Python


## Key

>关键词：Python 爬虫

### 设计思路

静态页面中使用`import requests`函数可以直接获取html页面信息，再使用BeautifulSoup库拉出xml，利用find_all方法可以获取指定标签的信息。但是在动态页面中的有效信息一般通过JavaScript脚本从数据库读信息。例如本次爬取[上海证券交易所](http://www.sse.com.cn/)的上市公司详情，定义在`'td'`标签下，静态页面中没有匹配，这时就只能用Selenium提取动态页面。

### Demo
```python
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
import os
import time
import csv
from lxml import etree
lis = []
temp = []
total = []
c = open("anhui.csv", "w")
writer = csv.writer(c)

for line in open("anhui.txt"):
	if line != '\n':
		# date = ''.join(date).strip('\n')
		lis.append(line[0:6])

print (lis)

for i in range(len(lis)):
	url = "http://www.sse.com.cn/assortment/stock/list/info/company/index.shtml?COMPANY_CODE="+str(lis[i])	
	driver=webdriver.Safari()
	driver.get(url)
	time.sleep(4)
	data = driver.page_source
	soup = BeautifulSoup(data, 'lxml')
	grades = soup.find_all('td')
	for grade in grades:
		temp.append(grade.get_text())
		print (grade)
	writer.writerow(temp)
	temp = []
	driver.quit()

c.close()
```

### 参考

- [Python](https://developer.apple.com)

